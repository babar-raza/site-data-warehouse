# GSC Data Warehouse - Hybrid Insight Engine
**Unified Analytics Platform combining Google Search Console & Google Analytics 4**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL 13+](https://img.shields.io/badge/postgresql-13+-blue.svg)](https://www.postgresql.org/)

---

## ğŸ¯ Overview

This is a production-ready **Hybrid Insight Engine** that implements the "ultimate sustainable plan" by combining:
- **Data Strategy:** Unified view joining GSC + GA4 metrics into a single golden table
- **Architecture:** Robust insight engine with detector pattern, repository persistence, and multi-agent intelligence

### What Makes This "Hybrid"?

Traditional approaches suffer from data silos:
- **GSC-only systems** can't see conversion data or user behavior
- **GA4-only systems** miss search visibility and ranking data

Our Hybrid Plan **fuses both** into `vw_unified_page_performance`, enabling insights like:
- ğŸ”´ "Page lost 45% clicks AND 30% conversions week-over-week" (correlated drop)
- ğŸŸ¡ "High GSC impressions but terrible GA4 conversion rate" (intent mismatch)
- ğŸŸ¢ "Impression spike +80% â€” opportunity to optimize CTR" (growth potential)

---

## ğŸ—ï¸ Architecture

### The Three Pillars

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              1. UNIFIED DATA LAYER                      â”‚
â”‚  vw_unified_page_performance (GSC âŠ• GA4)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ GSC Metrics  â”‚â—„â”€â”€â”€â–ºâ”‚ GA4 Metrics  â”‚                  â”‚
â”‚  â”‚ â€¢ Clicks     â”‚    â”‚ â€¢ Sessions    â”‚                  â”‚
â”‚  â”‚ â€¢ Impress.   â”‚    â”‚ â€¢ Conversions â”‚                  â”‚
â”‚  â”‚ â€¢ Position   â”‚    â”‚ â€¢ Engagement  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â–¼                    â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚ Time-Series Calculations            â”‚                â”‚
â”‚  â”‚ â€¢ Week-over-Week (WoW) changes      â”‚                â”‚
â”‚  â”‚ â€¢ Month-over-Month (MoM) trends     â”‚                â”‚
â”‚  â”‚ â€¢ Rolling 7/28-day averages         â”‚                â”‚
â”‚  â”‚ â€¢ Opportunity index, quality scores â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚               â”‚
     â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Anomaly    â”‚ â”‚Diagnosis â”‚ â”‚ Opportunity â”‚
â”‚ Detector   â”‚ â”‚ Detector â”‚ â”‚  Detector   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         2. INSIGHT ENGINE (Repository Pattern)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ InsightRepository (gsc.insights table)           â”‚   â”‚
â”‚  â”‚ â€¢ Deterministic IDs (prevents duplicates)        â”‚   â”‚
â”‚  â”‚ â€¢ Status workflow (new â†’ investigating â†’ fixed)  â”‚   â”‚
â”‚  â”‚ â€¢ Category: risk, opportunity, diagnosis, trend  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚               â”‚               â”‚
     â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Watcher  â”‚  â”‚Diagnosticianâ”‚  â”‚  Strategist  â”‚
â”‚  Agent   â”‚  â”‚   Agent     â”‚  â”‚    Agent     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚              â”‚                â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         3. MULTI-AGENT INTELLIGENCE LAYER               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ Message Bus  â”‚â—„â”€â”€â–ºâ”‚ State Managerâ”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚  Findings â†’ Diagnoses â†’ Recommendations                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âœ¨ Key Features

### ğŸ” Unified Analytics
- **GSC + GA4 fusion** in single view for holistic insights
- **Time-series analysis** with WoW/MoM percentage changes
- **Zero data loss** via FULL OUTER JOIN (handles missing GA4)
- **Fast queries** optimized with materialized views and indexes

### ğŸ¯ Intelligent Detection
- **AnomalyDetector:** Finds correlated drops (clicks + conversions)
- **DiagnosisDetector:** Root cause analysis (e.g., "drop after CMS update")
- **OpportunityDetector:** Growth potential (impression spikes, low CTR pages)
- **Hybrid rules:** Leverages both GSC and GA4 in detection logic

### ğŸ¤– Multi-Agent System
- **WatcherAgent:** Monitors data quality and collection status
- **DiagnosticianAgent:** Deep-dive analysis with hypothesis testing
- **StrategistAgent:** Generates actionable recommendations
- **DispatcherAgent:** Orchestrates agent pipeline with message bus

### ğŸ“Š Production-Ready
- **Idempotent operations:** Safe to re-run without side effects
- **Comprehensive logging:** Structured logs with correlation IDs
- **Health checks:** All services monitored with auto-restart
- **Docker Compose:** Single-command deployment

---

## ğŸš€ Quick Start

### Prerequisites
- **PostgreSQL 13+** (database)
- **Python 3.9+** (runtime)
- **Docker & Docker Compose** (containerization)
- **Google Cloud Service Account** with GSC API access
- **(Optional)** GA4 API credentials

### 1. Clone & Setup
```bash
git clone <repository-url>
cd gsc-data-warehouse

# Install dependencies
pip install -r requirements.txt

# Setup secrets (see deployment/SETUP_GUIDE.md)
cp secrets/gsc_sa.json.template secrets/gsc_sa.json
# Edit secrets/gsc_sa.json with your credentials
```

### 2. Database Setup
```bash
# Start PostgreSQL (via Docker)
docker-compose up -d warehouse

# Run schema migrations
for script in sql/*.sql; do
    psql $WAREHOUSE_DSN -f "$script"
done

# Verify setup
psql $WAREHOUSE_DSN -c "SELECT * FROM gsc.validate_unified_view_time_series();"
```

### 3. Initial Data Load
```bash
# Ingest GSC data (last 30 days)
python ingestors/api/gsc_api_ingestor.py \
    --date-start $(date -d '30 days ago' +%Y-%m-%d) \
    --date-end $(date +%Y-%m-%d)

# (Optional) Ingest GA4 data
python ingestors/ga4/ga4_extractor.py

# Refresh analytical views
python warehouse/refresh_views.py
```

### 4. Generate Insights
```bash
# Run Insight Engine
python -m insights_core.cli refresh

# View generated insights
psql $WAREHOUSE_DSN -c "
    SELECT 
        category,
        severity,
        title,
        description
    FROM gsc.vw_insights_actionable
    ORDER BY severity, generated_at DESC
    LIMIT 10;"
```

### 5. Start Services
```bash
# Start all services
docker-compose up -d

# Verify health
docker-compose ps

# View logs
docker-compose logs -f insights_engine
```

---

## ğŸ“ Project Structure

```
gsc-data-warehouse/
â”œâ”€â”€ sql/                          # Database schemas
â”‚   â”œâ”€â”€ 01_schema.sql            # GSC tables
â”‚   â”œâ”€â”€ 04_ga4_schema.sql        # GA4 tables  
â”‚   â”œâ”€â”€ 05_unified_view.sql      # â­ Hybrid unified view
â”‚   â”œâ”€â”€ 06_materialized_views.sql # Performance optimizations
â”‚   â””â”€â”€ 11_insights_table.sql    # Insights storage
â”‚
â”œâ”€â”€ insights_core/                # â­ Insight Engine (Hybrid)
â”‚   â”œâ”€â”€ engine.py                # Main orchestrator
â”‚   â”œâ”€â”€ models.py                # Pydantic models (Insight, etc.)
â”‚   â”œâ”€â”€ repository.py            # Database CRUD
â”‚   â”œâ”€â”€ config.py                # Configuration
â”‚   â”œâ”€â”€ detectors/               # Detection modules
â”‚   â”‚   â”œâ”€â”€ anomaly.py           # Finds GSC+GA4 anomalies
â”‚   â”‚   â”œâ”€â”€ diagnosis.py         # Root cause analysis
â”‚   â”‚   â””â”€â”€ opportunity.py       # Growth opportunities
â”‚   â””â”€â”€ channels/                # Output channels
â”‚       â”œâ”€â”€ slack.py             # Slack notifications
â”‚       â””â”€â”€ webhook.py           # Custom webhooks
â”‚
â”œâ”€â”€ agents/                       # Multi-Agent System
â”‚   â”œâ”€â”€ watcher/                 # Data monitoring
â”‚   â”œâ”€â”€ diagnostician/           # Analysis
â”‚   â”œâ”€â”€ strategist/              # Recommendations
â”‚   â”œâ”€â”€ dispatcher/              # Orchestration
â”‚   â””â”€â”€ base/                    # Shared infrastructure
â”‚       â”œâ”€â”€ message_bus.py       # Agent communication
â”‚       â””â”€â”€ state_manager.py     # Persistence
â”‚
â”œâ”€â”€ ingestors/                    # Data Collection
â”‚   â”œâ”€â”€ api/                     # GSC ingestion
â”‚   â”‚   â”œâ”€â”€ gsc_api_ingestor.py  # Main GSC collector
â”‚   â”‚   â””â”€â”€ rate_limiter.py      # API rate limiting
â”‚   â””â”€â”€ ga4/                     # GA4 ingestion
â”‚       â””â”€â”€ ga4_extractor.py     # GA4 data collector
â”‚
â”œâ”€â”€ mcp/                          # Model Context Protocol
â”‚   â””â”€â”€ mcp_server.py            # Claude interface
â”‚
â”œâ”€â”€ tests/                        # Test Suite
â”‚   â”œâ”€â”€ e2e/                     # End-to-end tests
â”‚   â”œâ”€â”€ agents/                  # Agent tests
â”‚   â”œâ”€â”€ test_detectors.py        # Detector tests
â”‚   â””â”€â”€ test_insight_repository.py # Repository tests
â”‚
â”œâ”€â”€ docs/                         # Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # System architecture
â”‚   â”œâ”€â”€ API_REFERENCE.md         # API documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md            # Deployment guide
â”‚   â””â”€â”€ deployment/              # Deployment runbooks
â”‚
â”œâ”€â”€ deployment/                   # â­ Deployment Scripts
â”‚   â”œâ”€â”€ windows/                 # Windows deployment
â”‚   â””â”€â”€ linux/                   # Linux deployment
â”‚
â”œâ”€â”€ docker-compose.yml           # Service orchestration
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

**â­ = Core Hybrid Plan components**

---

## ğŸ“ Usage Examples

### Query Unified View
```python
# Get pages with correlated drops (hybrid insight)
SELECT 
    page_path,
    gsc_clicks,
    gsc_clicks_change_wow,
    ga_conversions,
    ga_conversions_change_wow,
    opportunity_index
FROM gsc.vw_unified_page_performance
WHERE date >= CURRENT_DATE - INTERVAL '7 days'
    AND gsc_clicks_change_wow < -20  -- GSC drop
    AND ga_conversions_change_wow < -20  -- GA4 drop
ORDER BY gsc_clicks_change_wow;
```

### Programmatic Insight Detection
```python
from insights_core.engine import InsightEngine
from insights_core.config import InsightsConfig

# Initialize engine
config = InsightsConfig()
engine = InsightEngine(config)

# Run all detectors
stats = engine.refresh(property='sc-domain:example.com')

print(f"Created {stats['total_insights_created']} insights")
print(f"Breakdown: {stats['insights_by_detector']}")
```

### Query Insights via MCP
```python
# Claude Desktop can query via MCP server
# Tools available:
# - get_insights: Query insights by filters
# - get_insight_by_id: Retrieve specific insight
# - update_insight_status: Mark as investigating/resolved
```

---

## ğŸ§ª Testing

### Run Test Suite
```bash
# Unit tests
pytest tests/ -v

# Detector tests (verify hybrid logic)
pytest tests/test_detectors.py -v

# E2E tests (full pipeline)
bash tests/e2e/run_e2e_tests.sh

# Performance benchmarks
bash tests/e2e/test_performance.sh
```

### Manual Testing
```bash
# Verify unified view
psql $WAREHOUSE_DSN -c "SELECT * FROM gsc.validate_unified_view_time_series();"

# Test insight creation
python -c "
from insights_core.detectors import AnomalyDetector
from insights_core.repository import InsightRepository
from insights_core.config import InsightsConfig
import os

repo = InsightRepository(os.environ['WAREHOUSE_DSN'])
config = InsightsConfig()
detector = AnomalyDetector(repo, config)
count = detector.detect()
print(f'Created {count} insights')
"
```

See [`E2E_TEST_PLAN.md`](E2E_TEST_PLAN.md) for comprehensive testing guide.

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) | System architecture and design |
| [`docs/API_REFERENCE.md`](docs/API_REFERENCE.md) | API endpoints and schemas |
| [`docs/DEPLOYMENT.md`](docs/DEPLOYMENT.md) | Deployment instructions |
| [`docs/UNIFIED_VIEW_GUIDE.md`](docs/UNIFIED_VIEW_GUIDE.md) | Unified view deep-dive |
| [`docs/DETECTOR_GUIDE.md`](docs/DETECTOR_GUIDE.md) | Writing custom detectors |
| [`E2E_TEST_PLAN.md`](E2E_TEST_PLAN.md) | End-to-end testing guide |

---

## ğŸ”§ Configuration

### Environment Variables
```bash
# Database
export WAREHOUSE_DSN="postgresql://gsc_user:password@localhost:5432/gsc_db"

# GSC API
export GSC_SA_PATH="/path/to/gsc_sa.json"
export GSC_PROPERTY="sc-domain:example.com"

# GA4 (Optional)
export GA4_PROPERTY_ID="123456789"
export GA4_CREDENTIALS_PATH="/path/to/ga4_credentials.json"

# Insight Engine
export INSIGHTS_RISK_THRESHOLD=-20      # Clicks drop % threshold
export INSIGHTS_OPPORTUNITY_THRESHOLD=50 # Impressions spike % threshold
```

### Detector Thresholds
Customize in `insights_core/config.py`:
```python
class InsightsConfig:
    risk_threshold_clicks_pct: float = -20  # Traffic drop %
    risk_threshold_conversions_pct: float = -20  # Conversion drop %
    opportunity_threshold_impressions_pct: float = 50  # Impression spike %
```

---

## ğŸ› Troubleshooting

### Unified View Returns No Data
```bash
# Check if GSC data exists
psql $WAREHOUSE_DSN -c "SELECT COUNT(*) FROM gsc.fact_gsc_daily;"

# If zero, ingest data
python ingestors/api/gsc_api_ingestor.py --date-start 2024-11-01 --date-end 2024-11-15
```

### WoW Calculations Are NULL
- **Cause:** Need 7+ days of data for week-over-week
- **Solution:** Backfill historical data
```bash
python scripts/backfill_historical.py --days 30
```

### Detectors Create No Insights
- **Expected behavior** if traffic is stable (no anomalies)
- **Check for anomalies:**
```sql
SELECT COUNT(*) FROM gsc.vw_unified_anomalies;
```

### Agent Pipeline Fails
- **Check logs:** `docker-compose logs dispatcher`
- **Verify database permissions:** `GRANT ALL ON SCHEMA gsc TO gsc_user;`
- **Review agent execution history:**
```sql
SELECT * FROM gsc.agent_executions ORDER BY started_at DESC LIMIT 5;
```

---

## ğŸš¦ Deployment

### Production Deployment
See [`deployment/PRODUCTION_GUIDE.md`](deployment/PRODUCTION_GUIDE.md)

Quick deploy:
```bash
# Linux
./deployment/linux/deploy.sh

# Windows
deployment\windows\deploy.bat
```

### Monitoring
```bash
# View service status
docker-compose ps

# Check health endpoints
curl http://localhost:8000/health  # MCP server
curl http://localhost:8001/health  # Insights API (if enabled)

# View Grafana dashboards
open http://localhost:3000  # Default: admin/admin
```

---

## ğŸ¤ Contributing

### Adding a New Detector
```python
# insights_core/detectors/my_detector.py
from insights_core.detectors.base import BaseDetector
from insights_core.models import InsightCreate, InsightCategory

class MyDetector(BaseDetector):
    def detect(self, property: str = None) -> int:
        # 1. Query vw_unified_page_performance
        conn = self._get_db_connection()
        cur = conn.cursor()
        cur.execute("""
            SELECT * FROM gsc.vw_unified_page_performance
            WHERE <your conditions>
        """)
        rows = cur.fetchall()
        
        # 2. Analyze rows and create insights
        insights_created = 0
        for row in rows:
            insight = InsightCreate(
                property=row['property'],
                entity_type=EntityType.PAGE,
                entity_id=row['page_path'],
                category=InsightCategory.OPPORTUNITY,
                title="Your Title",
                description="Your description",
                severity=InsightSeverity.MEDIUM,
                confidence=0.8,
                metrics=InsightMetrics(...),
                window_days=7,
                source="MyDetector"
            )
            self.repository.create(insight)
            insights_created += 1
        
        return insights_created
```

Register in `insights_core/engine.py`:
```python
from insights_core.detectors.my_detector import MyDetector

self.detectors = [
    AnomalyDetector(self.repository, self.config),
    DiagnosisDetector(self.repository, self.config),
    OpportunityDetector(self.repository, self.config),
    MyDetector(self.repository, self.config),  # â† Add here
]
```

---

## ğŸ“Š Performance

### Benchmarks (100K rows)
- **Unified view query (30 days):** <2s
- **Insight detection (full refresh):** <30s
- **Agent pipeline (full execution):** <60s

### Scalability
- **Tested up to:** 10M rows in `fact_gsc_daily`
- **Materialized views:** Refresh in <5 minutes
- **Partitioning:** Date-based partitions recommended for >1 year data

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) file

---

## ğŸ™ Acknowledgments

Built using:
- **PostgreSQL** - Rock-solid data warehouse
- **Pydantic** - Data validation
- **Docker** - Containerization
- **FastAPI** - API framework (if using REST API)
- **Google APIs** - GSC & GA4 data sources

**Inspired by:** The need for holistic SEO + conversion analytics in a single platform.

---

## ğŸ“ Support

- **Documentation:** [`docs/`](docs/)
- **Issues:** GitHub Issues (if applicable)
- **Testing:** See [`E2E_TEST_PLAN.md`](E2E_TEST_PLAN.md)

---

**Ready to deploy?** See [`deployment/QUICKSTART.md`](deployment/QUICKSTART.md)

**Need help?** Check [`docs/TROUBLESHOOTING.md`](docs/TROUBLESHOOTING.md)
